{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-16T06:44:37.041611Z","iopub.execute_input":"2023-05-16T06:44:37.041996Z","iopub.status.idle":"2023-05-16T06:44:37.076002Z","shell.execute_reply.started":"2023-05-16T06:44:37.041966Z","shell.execute_reply":"2023-05-16T06:44:37.075281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output\n!pip3 install -U lazypredict\n!pip3 install -U pandas #Upgrading pandas\n\n#\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:44:37.077594Z","iopub.execute_input":"2023-05-16T06:44:37.078144Z","iopub.status.idle":"2023-05-16T06:45:04.096792Z","shell.execute_reply.started":"2023-05-16T06:44:37.078120Z","shell.execute_reply":"2023-05-16T06:45:04.095570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas\npandas.__version__","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:04.098436Z","iopub.execute_input":"2023-05-16T06:45:04.098758Z","iopub.status.idle":"2023-05-16T06:45:04.109441Z","shell.execute_reply.started":"2023-05-16T06:45:04.098729Z","shell.execute_reply":"2023-05-16T06:45:04.108507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n# 원핫인코딩할때 썼던 거(label encoder)랑 정확도 측정때 사용했던 것들(accuracy_score)? k겹 교차검증(kFold)에 test데이터 스플릿함수 import(자세힌 기억이...)\n\nfrom lightgbm import LGBMClassifier # LGBMClassifier가 지금 전체적으로 오류남.\nimport lazypredict\n# Lazy predict - 튜닝 없이 Basic 모델을 이용했을 때, 어떤 모델을 이용하면 좋은 결과를 얻을 수 있는지 확인할 수 있다. 단, 튜닝이 없기에 맹신은 금물.\n\nfrom lazypredict.Supervised import LazyClassifier # 얘도 마찬가지로 오류남.\n\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:04.111719Z","iopub.execute_input":"2023-05-16T06:45:04.112986Z","iopub.status.idle":"2023-05-16T06:45:08.097046Z","shell.execute_reply.started":"2023-05-16T06:45:04.112943Z","shell.execute_reply":"2023-05-16T06:45:08.096044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/spaceship-titanic/sample_submission.csv\")\n\nRANDOM_STATE = 12 \nFOLDS = 5\nSTRATEGY = 'median'","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.101619Z","iopub.execute_input":"2023-05-16T06:45:08.101931Z","iopub.status.idle":"2023-05-16T06:45:08.189311Z","shell.execute_reply.started":"2023-05-16T06:45:08.101904Z","shell.execute_reply":"2023-05-16T06:45:08.188429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.190356Z","iopub.execute_input":"2023-05-16T06:45:08.190654Z","iopub.status.idle":"2023-05-16T06:45:08.208009Z","shell.execute_reply.started":"2023-05-16T06:45:08.190628Z","shell.execute_reply":"2023-05-16T06:45:08.207055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'\\033[94mNumber of rows in train data: {train.shape[0]}')\nprint(f'\\033[94mNumber of columns in train data: {train.shape[1]}')\nprint(f'\\033[94mNumber of values in train data: {train.count().sum()}')\nprint(f'\\033[94mNumber missing values in train data: {sum(train.isna().sum())}')\n#format해서 출력하는 형태. 그냥 shape만 써도 충분하긴 할거 같음.","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.209275Z","iopub.execute_input":"2023-05-16T06:45:08.210068Z","iopub.status.idle":"2023-05-16T06:45:08.243507Z","shell.execute_reply.started":"2023-05-16T06:45:08.210046Z","shell.execute_reply":"2023-05-16T06:45:08.242258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'\\033[94m')\nprint(train.isna().sum().sort_values(ascending = False))\n#결측값 확인","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.246730Z","iopub.execute_input":"2023-05-16T06:45:08.246995Z","iopub.status.idle":"2023-05-16T06:45:08.264047Z","shell.execute_reply.started":"2023-05-16T06:45:08.246972Z","shell.execute_reply":"2023-05-16T06:45:08.263142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.265058Z","iopub.execute_input":"2023-05-16T06:45:08.265312Z","iopub.status.idle":"2023-05-16T06:45:08.294013Z","shell.execute_reply.started":"2023-05-16T06:45:08.265289Z","shell.execute_reply":"2023-05-16T06:45:08.293199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'\\033[94mNumber of rows in test data: {test.shape[0]}')\nprint(f'\\033[94mNumber of columns in test data: {test.shape[1]}')\nprint(f'\\033[94mNumber of values in train data: {test.count().sum()}')\nprint(f'\\033[94mNo of rows with missing values  in test data: {sum(test.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.295026Z","iopub.execute_input":"2023-05-16T06:45:08.295255Z","iopub.status.idle":"2023-05-16T06:45:08.311153Z","shell.execute_reply.started":"2023-05-16T06:45:08.295235Z","shell.execute_reply":"2023-05-16T06:45:08.310110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'\\033[94m')\nprint((test.isna().sum().sort_values(ascending = False)))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.312288Z","iopub.execute_input":"2023-05-16T06:45:08.312536Z","iopub.status.idle":"2023-05-16T06:45:08.335848Z","shell.execute_reply.started":"2023-05-16T06:45:08.312514Z","shell.execute_reply":"2023-05-16T06:45:08.334509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.337725Z","iopub.execute_input":"2023-05-16T06:45:08.338040Z","iopub.status.idle":"2023-05-16T06:45:08.367435Z","shell.execute_reply.started":"2023-05-16T06:45:08.338011Z","shell.execute_reply":"2023-05-16T06:45:08.366400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.368405Z","iopub.execute_input":"2023-05-16T06:45:08.368635Z","iopub.status.idle":"2023-05-16T06:45:08.377157Z","shell.execute_reply.started":"2023-05-16T06:45:08.368615Z","shell.execute_reply":"2023-05-16T06:45:08.376096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop([\"PassengerId\"] , axis = 1 , inplace = True)\ntest.drop([\"PassengerId\"] , axis = 1 , inplace = True)\nTARGET = 'Transported'\nFEATURES = [col for col in train.columns if col != TARGET]\nRANDOM_STATE = 12 \n\n# passenger id 제거, target은 transported 하지 못한것(False)에 맞추어 features 걸러냄.","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.378100Z","iopub.execute_input":"2023-05-16T06:45:08.378818Z","iopub.status.idle":"2023-05-16T06:45:08.389025Z","shell.execute_reply.started":"2023-05-16T06:45:08.378795Z","shell.execute_reply":"2023-05-16T06:45:08.388140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NULL 값들이 데이터에서 어떻게 분포해 있는지를 확인하는 코드.\n\ntest_null = pd.DataFrame(test.isna().sum())\ntest_null = test_null.sort_values(by = 0 ,ascending = False)\n# test data의 null값들을 뽑아서 값을 정렬한다.\ntrain_null = pd.DataFrame(train.isna().sum())\ntrain_null = train_null.sort_values(by = 0 ,ascending = False)[:-1]\n# train data의 null값들을 뽑아서 값을 정렬한다.\n\n# subplots를 활용해서 그래프 2개를 나란히 출력할수 있게 한다.\nfig = make_subplots(rows=1, \n                    cols=2,\n                    column_titles = [\"Train Data\", \"Test Data\"] ,\n                    x_title=\"Missing Values\")\n\n# 각각 그래프 추가\nfig.add_trace(go.Bar(x=train_null[0],\n                     y=train_null.index,\n                     orientation=\"h\",\n                    marker=dict(color=[n for n in range(12)], \n                                line_color='rgb(0,0,0)' , \n                                line_width = 2,\n                                coloraxis=\"coloraxis\")),\n              1, 1)\n\n# 각각 그래프 추가\nfig.add_trace(go.Bar(x=test_null[0], \n                     y=test_null.index,\n                     orientation=\"h\",\n                    marker=dict(color=[n for n in range(12)], \n                                line_color='rgb(0,0,0)', \n                                line_width = 2,\n                                coloraxis=\"coloraxis\")),\n              1, 2)\n\nfig.update_layout(showlegend=False, title_text=\"Column wise Null Value Distribution\", title_x=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.390037Z","iopub.execute_input":"2023-05-16T06:45:08.390277Z","iopub.status.idle":"2023-05-16T06:45:08.830512Z","shell.execute_reply.started":"2023-05-16T06:45:08.390257Z","shell.execute_reply":"2023-05-16T06:45:08.829599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 앞의 과정과 동일하게 진행하되, 이번엔 column이 아닌 row값 기준으로 분포를 구한다.\nmissing_train_row = train.isna().sum(axis=1)\nmissing_train_row = pd.DataFrame(missing_train_row.value_counts()/train.shape[0]).reset_index()\nmissing_test_row = test.isna().sum(axis=1)\nmissing_test_row = pd.DataFrame(missing_test_row.value_counts()/test.shape[0]).reset_index()\nmissing_train_row.columns = ['no', 'count']\nmissing_test_row.columns = ['no', 'count']\nmissing_train_row[\"count\"] = missing_train_row[\"count\"]*100\nmissing_test_row[\"count\"] = missing_test_row[\"count\"]*100\n\n\nfig = make_subplots(rows=1, \n                    cols=2,\n                    column_titles = [\"Train Data\", \"Test Data\"] ,\n                    x_title=\"Missing Values\",)\n\nfig.add_trace(go.Bar(x=missing_train_row[\"no\"], \n                     y=missing_train_row[\"count\"]  ,\n                    marker=dict(color=[n for n in range(4)], \n                                line_color='rgb(0,0,0)' ,\n                                line_width = 3\n                                ,coloraxis=\"coloraxis\")),\n              1, 1)\nfig.add_trace(go.Bar(x= missing_test_row[\"no\"], \n                     y=missing_test_row[\"count\"],\n                    marker=dict(color=[n for n in range(4)], \n                                line_color='rgb(0,0,0)',\n                                line_width = 3 ,\n                                coloraxis=\"coloraxis\")),\n              1, 2)\nfig.update_layout(showlegend=False, title_text=\"Row wise Null Value Distribution\", title_x=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.831832Z","iopub.execute_input":"2023-05-16T06:45:08.832089Z","iopub.status.idle":"2023-05-16T06:45:08.880928Z","shell.execute_reply.started":"2023-05-16T06:45:08.832063Z","shell.execute_reply":"2023-05-16T06:45:08.879762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train[FEATURES], test[FEATURES]], axis=0)\ntext_features = [\"Cabin\", \"Name\"]\n\n # nunique = unique한 갯수를 나타내는 함수 -> 값이 어느정도 이상이면 continuous, 아니면 categorical data\ncat_features = [col for col in FEATURES if df[col].nunique() < 25 and col not in text_features ]\ncont_features = [col for col in FEATURES if df[col].nunique() >= 25 and col not in text_features ]\n\ndel df\nprint(f'\\033[94mTotal number of features: {len(FEATURES)}')\nprint(f'\\033[94mNumber of categorical features: {len(cat_features)}')\nprint(f'\\033[94mNumber of continuos features: {len(cont_features)}')\nprint(f'\\033[94mNumber of text features: {len(text_features)}')\n\nlabels=['Categorical', 'Continuos', \"Text\"]\nvalues= [len(cat_features), len(cont_features), len(text_features)]\ncolors = ['#DE3163', '#58D68D']\n\nfig = go.Figure(data=[go.Pie(\n    labels=labels, \n    values=values, pull=[0.1, 0, 0 ],\n    marker=dict(colors=colors, \n                line=dict(color='#000000', \n                          width=2))\n)])\nfig.show()\n\n # 데이터의 종류(분포)를 확인","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.882323Z","iopub.execute_input":"2023-05-16T06:45:08.882619Z","iopub.status.idle":"2023-05-16T06:45:08.944159Z","shell.execute_reply.started":"2023-05-16T06:45:08.882595Z","shell.execute_reply":"2023-05-16T06:45:08.943555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.945066Z","iopub.execute_input":"2023-05-16T06:45:08.946194Z","iopub.status.idle":"2023-05-16T06:45:08.962569Z","shell.execute_reply.started":"2023-05-16T06:45:08.946141Z","shell.execute_reply":"2023-05-16T06:45:08.961421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_age = train.copy()\ntest_age = test.copy()\n\n# train데이터와 test데이터를 따로 라벨링하여 구분(합쳤을때 구분 가능하도록)\ntrain_age[\"type\"] = \"Train\"\ntest_age[\"type\"] = \"Test\"\n\n# train데이터와 test데이터를 합침\nageDf = pd.concat([train_age, test_age])\n\n# 나이의 분포를 히스토그램으로 나타내는 코드. \nfig = px.histogram(data_frame = ageDf, \n                   x=\"Age\",\n                   color= \"type\",\n                   color_discrete_sequence =  ['#58D68D','#DE3163'],\n                   marginal=\"box\",\n                   nbins= 100,\n                    template=\"plotly_white\"\n                )\nfig.update_layout(title = \"Distribution of Age\" , title_x = 0.5)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:08.963894Z","iopub.execute_input":"2023-05-16T06:45:08.964246Z","iopub.status.idle":"2023-05-16T06:45:10.231751Z","shell.execute_reply.started":"2023-05-16T06:45:08.964215Z","shell.execute_reply":"2023-05-16T06:45:10.227855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# singleimputer 를 이용해서 결측치를 채워주는 코드 - dropna와 다르게 평균값, 중앙값, 최빈값, 정해진 값 결측치를 채울 값을 정하는 방법이 정해져 있고,\n# 그 이미 정해진 strategy들 가운데에 하나를 골라 그 방법으로 결측치를 간단하게, 자동으로 채워줌.\nimputer_cols = [\"Age\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\" ,\"RoomService\"]\nimputer = SimpleImputer(strategy=STRATEGY )\nimputer.fit(train[imputer_cols])\ntrain[imputer_cols] = imputer.transform(train[imputer_cols])\ntest[imputer_cols] = imputer.transform(test[imputer_cols])\n\n# train과 test데이터에서 안들어간 값들은 Z로 채워넣음(임시)\ntrain[\"HomePlanet\"].fillna('Z', inplace=True)\ntest[\"HomePlanet\"].fillna('Z', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:10.232649Z","iopub.execute_input":"2023-05-16T06:45:10.232925Z","iopub.status.idle":"2023-05-16T06:45:10.258632Z","shell.execute_reply.started":"2023-05-16T06:45:10.232902Z","shell.execute_reply":"2023-05-16T06:45:10.257441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 문자로 된 데이터들로 이루어진 행들만 따로 모으기\nlabel_cols = [\"HomePlanet\", \"CryoSleep\",\"Cabin\", \"Destination\" ,\"VIP\"]\n\n# 라벨 인코딩(문자열 = 컴퓨터가 이해할 수 있도록 범주화) 해주는 코드\ndef label_encoder(train,test,columns):\n    for col in columns:\n        train[col] = train[col].astype(str)\n        test[col] = test[col].astype(str)\n        train[col] = LabelEncoder().fit_transform(train[col])\n        test[col] =  LabelEncoder().fit_transform(test[col])\n    return train, test\n\n# 라벨 인코딩 진행하기\ntrain ,test = label_encoder(train,test ,label_cols)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:10.259961Z","iopub.execute_input":"2023-05-16T06:45:10.260569Z","iopub.status.idle":"2023-05-16T06:45:10.312908Z","shell.execute_reply.started":"2023-05-16T06:45:10.260539Z","shell.execute_reply":"2023-05-16T06:45:10.311791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Name과 Cabin은 예측값에 영향을 주지 않으므로 drop을 이용해 제거\ntrain.drop([\"Name\" ,\"Cabin\"] , axis = 1 ,inplace = True)\ntest.drop([\"Name\" ,\"Cabin\"] , axis = 1 ,inplace = True)\n\n# X, y(train데이터와 그 데이터에 대한 정답) 분리\nX = train.drop(TARGET , axis =1)\ny = train[TARGET]\n\n# 그 중에서 train에 사용할 데이터와 test에 사용할 데이터로 또다시 분리\nX_train , X_test , y_train , y_test = train_test_split(X , \n                                                       y, \n                                                       random_state = 12 ,\n                                                       test_size =0.33)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:10.314219Z","iopub.execute_input":"2023-05-16T06:45:10.314502Z","iopub.status.idle":"2023-05-16T06:45:10.328395Z","shell.execute_reply.started":"2023-05-16T06:45:10.314478Z","shell.execute_reply":"2023-05-16T06:45:10.326848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 여러 모델들 중에서 가장 이 데이터를 예측하는데 적합한 모델을 찾기 위해\n# lazy predict를 수행하는 코드\nclf = LazyClassifier(verbose=0,\n                     ignore_warnings=True,\n                     custom_metric=None,\n                     predictions=False,\n                     random_state=12,\n                     classifiers='all')\n\nmodels, predictions = clf.fit(X_train , X_test , y_train , y_test)\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T07:05:29.428713Z","iopub.execute_input":"2023-05-16T07:05:29.429053Z","iopub.status.idle":"2023-05-16T07:05:43.892221Z","shell.execute_reply.started":"2023-05-16T07:05:29.429030Z","shell.execute_reply":"2023-05-16T07:05:43.890388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LGBM이 가장 정확도가 높은? 코드이므로 LGBM을 사용, 사용을 위해 lgb의 파라미터 설정.\nlgb_params = {\n    'objective' : 'binary',\n    'n_estimators' :50,\n    'learning_rate' : 0.08\n}\n\nlgb_predictions = 0\nlgb_scores = []\nlgb_fimp = []\n\n# 맨 마지막 열 제외하고 모든 데이터의 행들을 뽑아냄.\nLGBM_FEATURES = list(train.columns)[:-1]\n\n# K겹 교차검증과 LGBM을 동시에 수행\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(train[LGBM_FEATURES], train[TARGET])):\n    print(f'\\033[94m')\n    print(10*\"=\", f\"Fold={fold+1}\", 10*\"=\")\n    start_time = time.time()\n    \n    X_train, X_valid = train.iloc[train_idx][LGBM_FEATURES], train.iloc[valid_idx][LGBM_FEATURES]\n    y_train , y_valid = train[TARGET].iloc[train_idx] , train[TARGET].iloc[valid_idx]\n    \n    model = LGBMClassifier(**lgb_params)\n    model.fit(X_train, y_train,verbose=0)\n    \n    preds_valid = model.predict(X_valid)\n    acc = accuracy_score(y_valid,  preds_valid)\n    lgb_scores.append(acc)\n    run_time = time.time() - start_time\n    \n    fim = pd.DataFrame(index=LGBM_FEATURES,\n                 data=model.feature_importances_,\n                 columns=[f'{fold}_importance'])\n    lgb_fimp.append(fim)\n    \n    print(f\"Fold={fold+1}, Accuracy score: {acc:.2f}%, Run Time: {run_time:.2f}s\")\n    test_preds = model.predict(test[LGBM_FEATURES]) \n    lgb_predictions += test_preds/FOLDS\n    \nprint(\"\")\n\n# 각 시행 회차(K겹 교차검증)의 정확도를 출력\nprint(\"Mean Accuracy :\", np.mean(lgb_scores))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:20.845348Z","iopub.execute_input":"2023-05-16T06:45:20.845657Z","iopub.status.idle":"2023-05-16T06:45:23.172338Z","shell.execute_reply.started":"2023-05-16T06:45:20.845634Z","shell.execute_reply":"2023-05-16T06:45:23.171322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission파일로 제출하는 코드\nsubmission[TARGET] = lgb_predictions.astype(\"bool\")\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T06:45:23.173489Z","iopub.execute_input":"2023-05-16T06:45:23.173770Z","iopub.status.idle":"2023-05-16T06:45:23.193842Z","shell.execute_reply.started":"2023-05-16T06:45:23.173748Z","shell.execute_reply":"2023-05-16T06:45:23.191709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}