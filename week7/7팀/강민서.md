### 7주차

## 개념내용

### Process

1. 데이터셋 확인: null data확인, 수정
2. 탐색적 데이터 분석(EDA: Exploratory Data Analysis): 여러 feature 개별적으로 분석, 상관관계 확인(여러가지 시각화툴(그래프)이용)
3. feature engineering: 모델 성능 높이기 (one-hot encoding, class로 나누기, 구간으로 나누기, 텍스트 데이터 처리 등)
4. model 만들기: sklearn 사용 (딥러닝 위해 tensorflow, pytorch등 이용가능)
5. 모델 학습 및 예측: trainset을 가지고 모델 학습, testset으로 예측
6. 모델 평가: 성능 평가

- 데이터셋 확인
    - pandas 라이브러리 이용
    - 통계적 분석, 복잡한 처리 가능(메서드 이용)
    - pandas에 익숙해지자!
    - kaggle에서 데이터셋은 보통 tain, testset으로 나눠짐
- EDA
    - 데이터 분석을 위한 시각화 먼저
    - 시각화 라이브러리: matplotlib, seaborn, plotly 등
    1. Pclass: 서수형 데이터(카테고리이면서, 순서가 있음)
    2. Sex: pandas groupby와 seaborn countplot사용
    3. Age: histogram그려보기
    4. Embarked: 탑승한 항구
    5. Family: SibSp(형제자매) + Parch(부모): family size와의 관계 살펴보기
    6. Fare: 탑승요금 histogram, contious feature → 매우 비대칭, 모델에서 빼기
        - ourlier의 영향을 줄이기 위해 fare에 log취하기
        - dataframe의 특정 columns에 공통된 작업(함수) 적용하고 싶으면 map, apply 사용
        - fare columns의 데이터 모두를 log값 취하는 것인데, 파이썬의 간단한 lambda함수 이용해 간단한 로그 적용하는 함수를 map에 인수로 넣어주면, fare columns 데이터에 그대로 적용됨(유용함!기억하자!)
        
- Feature engineering
    - dataset에 존재하는 null data채우기
    - null data를 포함하는 feature의 statistics 참고
    - null data 처리에 따라 모델의 성능이 좌지우지됨
    - feature engineering은 실제 모델의 학습에 쓰려는 것이므로 test도 똑같이 적용해주어야함
    1. fill null : 이름의 문자를 바꿔주기( pandas series의 data를 string으로 바꿔주는 str method, 여기에 정규 표현식을 적용하게 해주는 extract method가 있음) 이를 사용해 이름의 문자 추출
        1. statistics활용
        2. null data없는 데이터 기반으로 머신러닝 알고리즘 만들어 예측
        3. statistics = train data의 것 의미 (우리는 test를 unseen으로 둔 상태로 두고 train에서 얻은 statistics를 기반으로 test의 null data를 채워줘야함)
    2. change age: age는 continuous feature인데 age를 몇 개의 group으로 나누어 category화 시켜주기(information loss가 생길수도 있음)
        1. dataframe의 indexing 방법인 loc 사용, 혹은 apply사용해 함수 넣어주기
        2. 간단하게 함수를 만들어 apply 메소드에 넣어주기
        3. 두 가지 방법이 같은 결과를 내야함 
        4. 확인하기 위해 Series간 boolean비교 후 all() 메소드 사용(모든 값이 True면 True, 하나라도 false가 있으면 false)
    3. change initial, embarked and sex(string to numerical)
        1. 수치화 해주기(map method)
        2. 사전 순서대로 mapping
        3. 특정 column에 어떤 값이 있는지 확인(unique()메소드, value_counts()를 통해 count 까지 확인
        4. feature간의 상관관계(-1로 갈수록 음의 상관관계, 1로 갈수록 양의 상관관계, 0은 상관관계 없음)
        5. matrix형태, heatmap plot으로 확인 (dataframe의 corr()메소드와 seaborn으로 그리기)
    4. data preprocessing(전처리) one-hot encoding on initial and embarked
        1. 수치화: master=0,miss=1,,,,이렇게 mapping
        2. 5차원의 벡터로 나타냄(pandas의 get_dummies사용)
    5. drop columns(필요한 거 말고 삭제)

- Building machine learning model and prediction using the trained model
    - Sklearn은 feature engineering, preprocessing, 지도 학습 , 비지도 학습 알고리즘, 모델 평가, 파이프라인 등 머신러닝에 관련된 모든 작업들이 손쉬운 인터페이스로 구현되어있음.
    - 데이터 분석 + 머신러닝을 위해 꼭 필요 <파이썬 라이브러리를 활용한 머신러닝>책 참고
    - 타이타닉 무제는 targel class가 0, 1로 이루어져 있으므로 binary classification문제이다
    - 그리고 test set으로 예측해보기
    1. preparation - split dataset into train, valid, test set
        1. 랜덤포레스트: 결정트리기반 모델
        2. 모델의 객체를 만들고 fit메소드로 학습
        3. 그 후 valid set input을 넣고 예측값 얻기
    2. model generation and prediction
    3. feature importance
        1. 어떤 feature에 영향을 많이 받았는지 확인
        2. pandas series 이용해 쉽게 sorting하여 그래프 그리
        3. feature importance = 지금 모델에서의 importance
    4. prediction on test set
        1. 테스트셋으로 예측
        2. submission
        

## 함수내용

```python
plt.style.use('seaborn') #matplotlib의 기본 scheme이 아닌 seaborn scheme세팅
sns.set(font_scale = 2.5) #폰트 사이즈 고전

df_train.head() #feature들과 target확인
df_train.describe() #feature들 통계치 반환

#Null Data Check
for col in df_train.columns: #null값 비율 확인: Age,Cabin,Embarked에 존재함 확인
    msg = 'column: {:>10}\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() / df_train[col].shape[0]))
    print(msg)

#msno 라이브러리를 사용해 더 쉽게 확인하기
msno.matrix(df=df_train.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))

sns.countplot(x='Survived', data = df_train, ax=ax[1]) 
#인터넷과 달리 x = 'Survived'라고 해줘야함

df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).count()
#'Pclass','Survived'를 가져와 pclass로 묶기, 평균내면 각 pclass별 생존률 알 수 있음

#pandas의 crosstab사용해 수월하게 보기
pd.crosstab(df_train['Pclass'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')

#grouped 객체에 mean()을 해서 각 클래스 별 생존률 얻기 
df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar()
#Pclass가 좋을 수록 생존률 높음

#생존에 따른 age histogram 그리기
fig, ax = plt.subplots(1, 1, figsize=(9, 5))
sns.kdeplot(df_train[df_train['Survived'] == 1]['Age'], ax=ax)
sns.kdeplot(df_train[df_train['Survived'] == 0]['Age'], ax=ax)
plt.legend(['Survived == 1', 'Survived == 0'])
plt.show()

#seaborn의 violinplot (x축, y축 지정해줘야함!)
#x축: case(Pclass,sex), y축: distribution(age)
f,ax=plt.subplots(1,2,figsize=(18,8))
sns.violinplot(x="Pclass",y="Age", hue="Survived", data=df_train, scale='count', split=True,ax=ax[0])
ax[0].set_title('Pclass and Age vs Survived')
ax[0].set_yticks(range(0,110,10))
sns.violinplot(x="Sex",y="Age", hue="Survived", data=df_train, scale='count', split=True,ax=ax[1])
ax[1].set_title('Sex and Age vs Survived')
ax[1].set_yticks(range(0,110,10))
plt.show()

#pandas dataframe 다룰 때 boolean array 이용해 indexing하는 방법이 편리함
#loc + boolean + column 을 이용해 값 치환 방법은 자주 사용됨

#dataframe 의 fillna method 를 이용,inplace=True 로 하면 df_train 에 fillna 를 실제로 적용
df_train['Embarked'].fillna('S', inplace=True)

```
