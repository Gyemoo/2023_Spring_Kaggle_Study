# 1강 - 캐글하는 이유
캐글은 2010년 설립된 빅데이터 대회 플랫폼 회사    
2017구글에 인수됨    
200만명 회원 보유    
기업이 데이터셋을 주고 대회를 열면 캐글에서 전세계 데이터 사이언티스트가 대회에 참여    
캐글에서 gpu와 함께 가상환경을 제공한다.(runtime 최대 2시간)    
검증된 캐글러들이 자신이 분석한 것을 공유하며 좋은 reference가 많다.    
# 2강 - 캐글로 얻어가는 것
지금까지 302개의 대회가 치러짐 -> 머신러닝으로 풀 수 있는 대부분의 문제가 담겨 있다.    
실력 향상, ml certification(자격증), 포트폴리오(프로필이 제공됨), 경험을 얻을 수 있다.    
캐글 자체가 직업을 주진 않지만, 실력을 쌓아서 직업을 얻을 수 있다. 가끔은 직접 컨택 될 수도.    
머신러닝은 개념을 배우는 것은 오래걸리지 않지만, 적절하게 활용하는 것이 어렵고 중요하다. 다른사람들의 아이디어를 읽자.    
데이터 시각화를 통한 통찰력. 파이썬 머신러닝 완벽가이드.    
exploaraty data analysis, feature engineering, data preparation, model development, model evaluation 등의 순서로 진행함. 실제로 이때까지 했을때도 이렇게 했었던 것 같음(데이터 입력, EDA, 전처리, 모델생성, 모델평가)    
# 3강 - 머신러닝 자기 경험 설명
머신 러닝 = 패턴 학습.     
데이터가 가장 중요하다.     
모델을 만들었을 때 성능이 안나온다면 모델을 바꾸는것보다 데이터를 다시 보는게 더 좋을 정도로 중요.    
대회는 팀으로 참여하는 것이 좋다.    
### 1. nulldata 확인     
### 2. outlier 확인(kaggle에 공유되는 경우 많음)      
###
+ ratio features(A per B)      
+ product feature(상위 feature곱하기)      
+ addition or subtraction features(중요한 feature 합, 차)      
+ new categorical features(특정 조건 만족 기준으로 이진 카테고리) -tree모델은 스무고개(?) - 강력한 한방       
+ aggregation features(각 그룹의 numerical features(mean, median, variance, standard deviation 등)을 조합해서 만듬.)      
+ numerical features – continuous 한거       
+ categorical features – 순서가 없는거      
### 3. feature engineering(one hot encoding, label encoding, lightgbm built in)등등
feature selection(주요한 feature만 고르는 방법)      
LGBM(성능이 좋고 빠르다 – random forest는 느려서...)      
하나의 강력한거보다 여러개를 그냥 합치는게 더 좋다.(stack, ensemble - 앙상블)      
+ 여기서 추가로 성능을 올리려면 성능을 더 올리려면 feature generation, more stacking,  parameter tuning 해야 한다(이 순서로 하는게 좋음).      
특히, feature generation과 cross-validation은 함께 해야 한다.      
+ kaggle의 리더보드의 순위가 절대적인게 아님(private 리더보드도 있음)       
+ 제출시 나오는 리더보드의 스코어와 내 시스템하고 얼마나 맞는지 확인해라. validation dataset을 많이 만들어라. 여러번 해보다보면 가장 리더보드 스코어랑 비슷한?게 있는데 그게 test 데이터랑 가장 비슷하다?      
다른 사람의 kernel에 있는 설명이나 코드를 보고 배울 수 있다.      
# 4강 - Kaggle 사용법
overview, dataset 살펴보아야 함.      
metric – 평가할 수치      
kernel – most votes 순으로 정렬해서 위에서부터 보는게 좋음.       
+ 이것들은 opensource       
+ 여기서 이 업계에서 많이 쓰는 단어들 알 수 있다.      
+ 그림 그렸을 때 해석하는 방법 확인할 수 있다.(EDA)      
따라적기하면서 공부해라.      
discussion – most votes순.      
kernal 생성하는 법. - notebook 선택, settings에서 확인,        
upload ipynb 기능으로 ipynb파일을 집어 넣을수도 있고      
download ipynb 기능으로 작성한 ipynb파일을 외부로 추출할수도 있다.      
tip - esc누르면 셀을 편집하게 되는데, 그 상태로 b를 누르면 셀이 많이 생성됨, 그 상태로 진행하는게 편하다.       
랭킹시스템 – novice, contributor, expert, master      
contributor까지는 해두는게 좋음.      
expert 빨리 올라갈려면 좋은 커널 몇 개 작성하면 됨. 잘한다는 정도.      
compettition으로 딴 kaggle master는 사실상 논문 작성이랑 거의 동급. 남들이 봤을 때 잘했다고 할 수 있을정도로 확실하게 인정받을정도이다.      
grandmaster는 세계 최강자급이라고 봐도 될듯.      

