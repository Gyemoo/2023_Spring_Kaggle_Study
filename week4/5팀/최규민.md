# kaggle Data Analysis
## 1. what is kaggle?
> 구글이 인수한, 200만명의 회원을 보유하고 있는, Data science, ML, DL을 주제로 모인 community

### 3 parts of kaggle
- competitions: 공모전
- kernels: 개발 환경
- discussion: 커뮤니티

### how kagglers get in competition?
기업, 정부기관, 단체, 연구소, 개인이 dataset과 prize를 캐글에 제시하면, 캐글이 회원으로 등록된 전 세계 데이터 사이언티스트들에게 competition 형태로 제공

### benefits
커널 제공, 검증된 reference와 공부 자료

---
## 2. why do kaggle?
- 2018년 기준 302차례의 competition이 치뤄진 만큼, 머신러닝으로 풀 수 있는 대부분의 문제가 담겨있다.
### what can i get from kaggle?
- 실력 향상
- ML certificate
- portfolio : 캐글 프로필 기능으로 증빙 가
- 경험

> 캐글이 job을 주진 않으나, 캐글을 통해 쌓은 ML, DL, DS 실력이 구직에 도움이 된다.

### 정형 데이터 분석
- Exploratory Data Analysis
  - Data visualization
    - Matplotlib, Seaborn, Plotly
    - Data Mining
    - Pandas, numpy
- Data Preparation
  - Data augmentation(imbalance)
    - Upsampling
    - Downsampling
    - SMOTE
- Feature Engineering
  - Time series features
  - Categorical features
  - Numerical features
  - Aggregation features
  - Ratio features
  - Product features
- Model Development
  - Sklearn
    - Linear model
    - Non-linear model
    - Tree-model
  - Not sklearn
    - Xgboost
    - Lightgbm
    - Catboost
    - LibFFM
- Model Evaluation
  - Various metrics
    - Accuracy
    - Precision
    - Recall
    - F1-score
    - Etc.
- Other technique
  - Machine learning pipeline
    - My pipeline code
  - Feature management

## how to get into competition
### what is ML?
- Patter recognition
  - making general function(conditions) to obtain goal(minimize loss)
  - learn statistic(correlations) between feature vs feature / feature vs target
> *Your neural network is only as good as the data you feed it.*
/
> ex.
> 1. data check - outlier check, null daa check, feature check, outlier check
> 2. feature engineering - ratio, product, addition or subtraction, new categorial, aggregation, categorical, fill missing values and infinite values, use various approaches
> 3. model development - use LGBM
> 4. training strategy - ensemble is always answer
> 5. stacking and averaging
> for further upgrade.... feature generation, parameter tuning, more stacking

### bottom-up feature selection
feature generation -> cross validation system -> cv elivation -> if -> featset update


