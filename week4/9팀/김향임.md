# 1~4주차 영상 요약


## 1강 : What is Kaggle?

- kaggle
    - Data science, ML, DL을 주제로 모인 community
    
    
- kernel
    - Kaggle에서 제공하는 가상환경
    - 캐글 사용자들이 자신이 분석한 것을 공유



## 2강 : Why do Kaggle?

- Kaggle을 통해 ML certificate, Portfolio, 경험을 쌓을 수 있음
- Kaggle이 Job에 직접적 도움 Xx → But, Job을 구하는데 도움을 줌


- 개인적 측면 (About 정형데이터)
    - Proto : 고객의 보험금 청구 여부
    - Home Credit : 고객의 대출 상환 여부
    - Costa rican : 고객 수준 ML으로 구분
    - Elo : 고객 데이터 바탕 충성도 예측
    - New York taxi : 택시 탑승 시간 예측
    - 직방 : 아파트 거래가격 예측
    - INFOCAF : 아파트 거래가격 예측
    
    
- 개인적 측면 (About 딥러닝)
    - Tensorflow : 30개 단어 구분
    - Quora : 질문 성질 구분
    - Doodle : 낙서 ANN으로 구분
    - Protein : Protein ANN으로 구분
    - Airbus : 위성사진으로 배 위치 탐색
    - Statoil : 바다 위 빙산, 배 구


- 요즘 트렌드 → ML, DL 대회 多


## 3강 : Kaggle 컴퍼티션 참여 방법

- 데이터 분석 VS 알고리즘 선택
    - ‘데이터’부터 봐야함
    - 데이터에 숨겨져 있는 pattern, correlation을 AI가 찾았다
    - **가장 중요한 것은 DATA !!**
    
- Kaggle Data process


1. Data Check → Outlier Check
2. Feature engineering
    1. → Product feature : Feature important를 보고 상위 feature들 중 numercal feature끼리 곱해서 추가함
    2. → Addition or Subtration features : 중요한 feature끼리 더하거나 빼서 새로운 feature 생성
    3. → New categorical feature : 특정 기준에 맞춰 Binary Category를 만들 수 있음
    4. → Aggregation feature : Category와 numercial feature의 조합으로 생성
    - 원-핫 인코딩 : 카테고리의 개수만큼 칼럼이 늘어남 → 너무 오래걸림
    - 라벨 인코딩 : 자칭 Bias ordering 문제 발생 가능
    - Lightgbm Built-in : 데이터 셋이 큼 → Lightgbm 사용 → 카테고리 처리 내장 알고리즘 있음 !
3. Feature Selection → Use various approaches (feature을 추려냄)
4. Model development → Use LGBM 
5. Training strategy → Ensemble is always answer
6. Stacking and Averaging (ex : 다른 사람 것과 합침)


- 성능을 향상시키기 위해서는
    - Feature generation
    - Parameter tuning
    - More stacking

⇒ Feature generation과 Cross-validation은 함께

## 4강 : Kaggle 사용법


- Titanic Data 이용해서 사용법 알아보기
    - Titanic Data 설명 …
    
- Kaggle Kernels에 올라온 여러 코드, 데이터들 잘 활용해서 배우기
